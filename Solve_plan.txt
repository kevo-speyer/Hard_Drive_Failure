Plan to Solve problem:

1) Explore data to get the most important attributes using T-test and ANOVA. 
   Divide population by tag ( failure = 0, failure = 1 ), and see which attributes
display a significant different distribution in each group. Dimension of the problem should decrease notably.

Done with T-test! Run exploration.py to see output of this stage (and be patient, might take ~ 5min) 

Optional) Get the optimum linear combination of relevant attributes by doing a PCA. See wether dimensionality can be brought down even more (Maybe not necessary)

3 y 4) Implement algorithms to predict failure:
   - Logistic Regresion ( DONE! works fairly good 0.78 +/- 0.04 AUC in CV)
   - ADA Boosting ( DONE! Shit in CV AUC < 0.5 ) 
   - Random Forest ( DONE! Works good AUC in CV = 0.78 +/- 0.04, ROC looks weird)
   - k-neares neighbors ( Training is too slow ... )


